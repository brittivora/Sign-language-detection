# Real-Time Sign Language Detection

A real-time sign language recognition system built using **MediaPipe**, **OpenCV**, **TensorFlow**, and **Streamlit**. The system detects and classifies hand gestures (`hello`, `thanks`, `yes`, `no`) using webcam input and deep learning-based sequence modeling.

---

## ðŸ“Œ Project Overview

This project captures and processes hand landmarks from webcam video frames, builds temporal sequences, and classifies them using an **LSTM neural network**. It includes:

- **Data Collection** using OpenCV
- **Keypoint Extraction** using MediaPipe Hands
- **Sequence Modeling** using LSTM
- **Real-Time Inference** using Streamlit web interface

---

## ðŸ§  Model Architecture

- **Input**: Sequences of 10 frames, each frame represented as a 126-dimensional vector (2 hands Ã— 21 landmarks Ã— 3D coords).
- **Model**: 
  - LSTM layers: `[64 â†’ 64 â†’ 32]`
  - Dense layers: `[64 â†’ 32 â†’ 4 (softmax)]`
- **Framework**: TensorFlow/Keras
- **Output**: Probability distribution over 4 classes: `hello`, `thanks`, `yes`, `no`.

---


